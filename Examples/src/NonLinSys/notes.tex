\documentclass[12pt,twoside]{article}
\usepackage{amsmath,amssymb}
\usepackage{a4wide}
\begin{document}
Here you find a simple set of codes for the problem: find $\mathbf{x}$ such that
\[
\mathbf{F}(\mathbf{x})=\mathbf{0}
\]
for a $F:\mathbb{R}^n\to\mathbb{R}^n$ (which we assume to be at least Lipschitz continuous).

The set of codes include a class to store non linear systems, a class thet implements Newton method and another for a genetic fixed point iteration.
\section{The class for non linear systems}

\section{The methods implemented}
\subsection{Newton Method}
We indicate with $\boldsymbol{J}(\mathbf{x})$ the Jacobian (Frechet derivative) of $\mathbf{F}$ at $\mathbf{x}$. The algorithm implements a simple backtraching
based on Armijo rule with constant reduction of the step $\lambda$.

Let $\mathbf{x}$ be given, together with a small positive number $\sigma$ and
$\gamma\in (0,1)$
\begin{enumerate}
\item Compute $\mathbf{d}$ by solving
$
\boldsymbol{J}(\mathbf{x})\mathbf{d}=-\mathbf{F}(\mathbf{x}).
$
\item $\lambda=1$.
\item Until $\Vert\mathbf{F}(\mathbf{x}+\lambda\mathbf{d})\Vert< (1-\lambda\sigma)\Vert \mathbf{F}(\mathbf{x}\Vert$ set $\lambda\leftarrow
\gamma\lambda$
\item Set $\mathbf{x}\leftarrow\mathbf{x}+\lambda\mathbf{d}$
\item Check for convergence.
\end{enumerate}
Convergence test is made by checking the residual $\mathbf{F}(\mathbf{x})$, the
step length $\Vert \mathbf{d}\Vert$ and fixing a maximum number of iterations.

Step 3 implements Armijo rule for sufficient decrease of $\Vert\mathbf{F}\Vert$.

\section{Notes}
The architecture of this code can be bettered. First of all one can generalize the class fixed point to accept any iteration function $\boldsymbol{\Phi}(\mathbf{x})$ and implements
\[
\mathbf{x}_{k+1}=\boldsymbol{\Phi}(\mathbf{x}_k), \quad k=1,\ldots
\]
for a given $\mathbf{x}_0$.

In this respect Newton method is just a  particular fixed point iteration with iteration function
\[
\boldsymbol{\Phi}_N(\mathbf{x})=\mathbf{x}-\boldsymbol{J}^{-1}(\mathbf{x})\mathbf{F}(\mathbf{x})
\]

However Newton method can be seen as a particular \emph{line search method}. So one may think to create an abstract class (or a template) for generic line search methods and specialise it for different type of algorithms, using for instance a stategy pattern via policies. Algoritms may include gradient, conjugate gradient (in different forms), Broyden etc etc. It may also implement different backtracking strategies (armijo, Wolfe....) 
All algoritms of the form
\begin{itemize}
\item Compute a descent direction $\mathbf{d_k}$
\item Compute the step $\mathbf{\alpha}_k$ according to a backtracking strategy
\item Update $\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k\mathbf{d}_k$.
\end{itemize}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
